{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d821e87-a5a4-4cd9-953b-e35baff22cd5",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88dfed0-1022-4ce2-b6fe-5a841d3564a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c724952-8c91-4414-bc5e-752949c78e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHEXPERT_BASE_DIR_LABEL = \"C:\\\\Users\\\\Mohammed Arshan\\\\Downloads\\\\archive\\\\CheXpert-v1.0-small\"\n",
    "CHEXPERT_BASE_DIR = \"C:\\\\Users\\\\Mohammed Arshan\\\\Downloads\\\\archive\"\n",
    "#had to create two different filepaths as it was leading to an error\n",
    "TRAIN_CSV_PATH = os.path.join(CHEXPERT_BASE_DIR_LABEL, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76465e32-6e2c-4355-a457-4bfac088ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for fast prototyping\n",
    "SUBSAMPLE_SIZE = 5000\n",
    "BATCH_SIZE = 32\n",
    "TARGET_EPOCHS = 1\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87be8119-e385-4917-ae5c-07605c5c4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five Official CheXpert Benchmark Labels\n",
    "TARGET_LABELS = [\n",
    "    'Atelectasis', \n",
    "    'Cardiomegaly', \n",
    "    'Edema', \n",
    "    'Consolidation', \n",
    "    'Pleural Effusion'\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589950bd-2ca7-4e42-9543-fd0da4f99b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Ones Strategy: Treat uncertainty (-1) as POSITIVE (1) for these specific labels\n",
    "U_ONES_LABELS = ['Edema', 'Cardiomegaly', 'Atelectasis', 'Pleural Effusion'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c1888c3-791a-4bb1-8c98-e0bd6cc1e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f041a8-6c78-4292-b223-0d4e12faae40",
   "metadata": {},
   "source": [
    "Custom Dataset Class and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29922e94-c1f3-4ffc-8a66-d170d805b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_dir, transform=None):\n",
    "        self.df = dataframe #Stores the input DataFrame \n",
    "        self.base_dir = base_dir #Stores the base directory path\n",
    "        self.transform = transform #Stores the image transformations\n",
    "        self.labels = dataframe[TARGET_LABELS].values.astype(np.float32) #Extracts the label columns from the DataFrame, converts them into a NumPy array, and casts the data type to 32-bit floating point, which is standard for deep learning model inputs/outputs.\n",
    "    \n",
    "    def __len__(self): #Defines the length method, which is required by PyTorch Dataset\n",
    "        return len(self.df)\n",
    "\n",
    "    #Defines the core item getter method, which is required by PyTorch Dataset and is called by the DataLoader to retrieve a single sample given an idx (index).\n",
    "    def __getitem__(self, idx):\n",
    "        # Construct full image path\n",
    "        img_path_relative = self.df.iloc[idx]['Path'] #Retrieves the relative image path\n",
    "        img_path = os.path.join(self.base_dir, img_path_relative)\n",
    "\n",
    "        # Load image (Grayscale or RGB)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        #.convert('RGB') ensures the image is read with three color channels, even if the original image is grayscale\n",
    "\n",
    "        # Apply transforms (resize, normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get labels\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6934a2-d0f3-41b3-b578-2f7928d005f2",
   "metadata": {},
   "source": [
    "Data Loading and U-Ones Strategy Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b79e8af-531f-49d1-a502-577cd06c4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160fe3f1-6aca-418b-955d-16d888a00cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling and U-Labeling\n",
    "df_train_subsampled = df_train.sample(n=SUBSAMPLE_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e826ba93-d3dd-4ff6-8ec8-5514bb16a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in TARGET_LABELS:\n",
    "    # Fill NaN with 0\n",
    "    df_train_subsampled[label] = df_train_subsampled[label].fillna(0)\n",
    "\n",
    "    if label in U_ONES_LABELS:\n",
    "        # U-Ones strategy: Replace -1 (Uncertain) with 1 (Positive)\n",
    "        df_train_subsampled[label] = df_train_subsampled[label].replace({-1: 1})\n",
    "    else:\n",
    "        # U-Zeros strategy: Replace -1 (Uncertain) with 0 (Negative)\n",
    "        df_train_subsampled[label] = df_train_subsampled[label].replace({-1: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c560d59-6b4b-47af-bca8-302dacf6be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation Split\n",
    "train_df, test_df = train_test_split(df_train_subsampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8361f6dd-9ae4-4247-8852-03994fb85c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transforms\n",
    "# Use ImageNet normalization as we are using a model pre-trained on ImageNet\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd66055-8a51-434f-83b5-67faf8d552a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader instances\n",
    "train_dataset = CheXpertDataset(train_df, CHEXPERT_BASE_DIR, data_transforms)\n",
    "val_dataset = CheXpertDataset(test_df, CHEXPERT_BASE_DIR, data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44bd3bf7-b069-4229-acde-21b1bc2836ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3b6ea-db1d-444d-b8d8-336006ef44e2",
   "metadata": {},
   "source": [
    "Model Setup (DenseNet121 TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97cc1f9c-b16b-47e8-ba0e-1048e8b592c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_densenet_model(num_classes):\n",
    "    # Load the pre-trained DenseNet121 model\n",
    "    # Using 'DEFAULT' to get the recommended ImageNet weights\n",
    "    model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "\n",
    "    # Freeze all the parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the final classification layer (model.classifier)\n",
    "    num_ftrs = model.classifier.in_features\n",
    "\n",
    "    # New classifier for NUM_CLASSES with Sigmoid activation for multi-label\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, num_classes),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60130424-d21d-45f2-a478-dba078a2fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setup_densenet_model(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18465767-3cca-4247-9ae6-827757f37fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Binary Cross-Entropy Loss (BCE) for multi-label classification\n",
    "# nn.BCELoss expects Sigmoid output (which we added to the model)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer only updates the new, unfrozen classifier layers\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450fdadb-66d8-48eb-a3dd-7e5e42dfbc1a",
   "metadata": {},
   "source": [
    "Training and Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0a1b188-8737-4978-9bd0-5ad6d51f2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, valid_loader, epochs):\n",
    "    history = {'train_loss':[], 'val_auc':[]}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            #loss.item() gets the Python number for the loss, and multiplying by inputs.size(0) (the batch size) ensures the loss is weighted by the sample count.\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        #  Validation Phase\n",
    "        model.eval()\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        with torch.no_grad(): #Disables gradient tracking within this block\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy()) #Moves the labels back to the CPU and converts them to a NumPy array before appending them to the list.\n",
    "                all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_preds = np.array(all_preds)\n",
    "\n",
    "        # Calculate AUC for each of the 5 labels and take the mean\n",
    "        # roc_auc_score handles multi-label inputs directly\n",
    "        try:\n",
    "            val_auc = roc_auc_score(all_labels, all_preds, average='macro')\n",
    "        except ValueError:\n",
    "            # Occurs if a class has no positive examples in the small subsample\n",
    "            val_auc = 0.5 \n",
    "\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['val_auc'].append(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {epoch_loss:.4f} | Val AUC (Macro): {val_auc:.4f}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061bc082-6102-47da-9746-ec08f11d64a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Train Loss: 0.5104 | Val AUC (Macro): 0.6416\n"
     ]
    }
   ],
   "source": [
    "#Run the training\n",
    "history = train_model(model, criterion, optimizer, train_loader, val_loader, TARGET_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56e6a3f0-a86f-4d7b-b887-9359a2f0dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model weights\n",
    "#Define a path to save the state dictionary\n",
    "MODEL_SAVE_PATH = 'densenet121_chexpert_tl_weights.pth'\n",
    "\n",
    "# Save only the state dict (weights)\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
