{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0xE0ufvXe0Z"
   },
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kde_2UEhXeFA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q7C5VXHmXhWJ"
   },
   "outputs": [],
   "source": [
    "#defining constants\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ROcBClJVYSGn"
   },
   "outputs": [],
   "source": [
    "#Standard CIFAR-10 transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) #channel-wise mean and standard deviation calculated across the entire CIFAR-10 training dataset\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TTVL4T5a2jMf"
   },
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDomjmoOY-lg"
   },
   "source": [
    "Custom DenseNet building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jENEF-ElbjY5"
   },
   "source": [
    "The core purpose of a Bottleneck layer is to improve computational efficiency in deep networks by reducing the number of input feature maps before applying the more computationally expensive 3×3 convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NhmlchXdY6_v"
   },
   "outputs": [],
   "source": [
    "class _Bottleneck(nn.Module):\n",
    "  def __init__(self, in_channels, growth_rate): #Standard Bottleneck layer (BN -> ReLU -> 1x1 Conv -> BN -> ReLU -> 3x3 Conv)\n",
    "    #in_channels = the number of input feature maps to this layer\n",
    "    #growth_rate = the number of output feature maps this layer will contribute to the DenseNet block\n",
    "    super().__init__() #Calls the constructor of the parent class, nn.Module, which is necessary for proper PyTorch module initialization.\n",
    "    # BN -> ReLU -> 1x1 Conv (Bottleneck)\n",
    "    self.norm1 = nn.BatchNorm2d(in_channels)\n",
    "    self.relu1 = nn.ReLU(inplace=True) #inplace=True saves memory by modifying the input directly.\n",
    "    self.conv1 = nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, stride=1, bias=False) # 4 * growth_rate (G) is a standard bottleneck ratio\n",
    "    #It takes in_channels and reduces the channel count to 4×growth_rate. The 1×1 kernel changes channels but not the spatial resolution. bias=False is standard when followed immediately by Batch Normalization\n",
    "\n",
    "    # BN -> ReLU -> 3x3 Conv\n",
    "    self.norm2 = nn.BatchNorm2d(4 * growth_rate)\n",
    "    self.relu2 = nn.ReLU(inplace=True)\n",
    "    self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    #It takes the 4×growth_rate channels and transforms them into growth_rate output channels. The 3×3 kernel and padding=1 ensure the output feature map has the same spatial dimensions as the input, which is essential for concatenation in DenseNet\n",
    "\n",
    "  def forward(self, x):\n",
    "    # The input x is concatenated output from all previous layers\n",
    "    out = self.conv1(self.relu1(self.norm1(x)))\n",
    "    out = self.conv2(self.relu2(self.norm2(out)))\n",
    "    # Output is concatenated with input in the DenseBlock\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkvdzrOBgYyz"
   },
   "source": [
    "A Dense Block is a core component of the Dense Convolutional Network (DenseNet) architecture. Its key idea is dense connectivity, where every layer within the block is connected to every other layer in a feed-forward fashion.\n",
    "\n",
    "Specifically, for each layer l within a Dense Block, the feature maps of all preceding layers (0,1,…,l−1) are concatenated along the channel dimension and used as input for layer l. The output of layer l is then passed on as input to all subsequent layers (l+1,…)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dmVDd77hekKm"
   },
   "outputs": [],
   "source": [
    "class _DenseBlock(nn.Module):\n",
    "  def __init__(self, num_layers, in_channels, growth_rate):\n",
    "    #num_layers: The number of individual convolution layers (bottleneck layers) inside this dense block.\n",
    "    super().__init__()\n",
    "    self.layers = nn.ModuleList() #This is a list specifically designed to hold sub-modules (_Bottleneck layers in this case).\n",
    "    for i in range(num_layers):\n",
    "      layer_input_channels = in_channels + i * growth_rate\n",
    "      #Calculates the required number of input channels for the current layer (i).\n",
    "      #in_channels: The initial number of feature maps from outside the block.\n",
    "      #i * growth_rate: The total number of new feature maps added by all previous i layers within this block.\n",
    "      #The sum is the total number of channels that will be concatenated and fed as input to the current layer.\n",
    "      self.layers.append(_Bottleneck(layer_input_channels, growth_rate)) #Creates a new _Bottleneck module\n",
    "\n",
    "  def forward(self, init_features): #init_features: The initial feature maps (tensors) coming into the dense block.\n",
    "    features = [init_features] #Initializes a list called features. This list will store the feature maps from the initial input and the output of every subsequent layer in the dense block.\n",
    "    for layer in self.layers:\n",
    "      #This is the core of the dense connectivity:\n",
    "      #torch.cat(features, 1): All feature maps currently stored in the features list (the initial input + all previous layer outputs) are concatenated (stacked) along the channel dimension (dimension 1 in PyTorch's common N×C×H×W format). This becomes the input to the current layer.\n",
    "      #layer(...): The concatenated features are passed through the current _Bottleneck layer, producing a tensor of growth_rate number of channels, called new_features.\n",
    "      new_features = layer(torch.cat(features, 1))\n",
    "      features.append(new_features) #The newly generated feature maps are added to the features list. This ensures that the output of the current layer will be included in the concatenated input for all subsequent layers.\n",
    "\n",
    "    return torch.cat(features, 1) #After all layers in the block have been processed, the function returns the final output of the dense block by concatenating all the feature maps stored in the features list (the initial input + the output of all N layers). This composite feature map is then typically passed to a Transition Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW1o6sA1kb86"
   },
   "source": [
    "The transition layers are placed between Dense Blocks to control the model's complexity by reducing the spatial size and reducing the number of feature channels, while still allowing the DenseNet to benefit from its core feature reuse and strong gradient flow properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DqXkSgNwjADV"
   },
   "outputs": [],
   "source": [
    "class _Transition(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super().__init__()\n",
    "    self.norm = nn.BatchNorm2d(in_channels)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    # 1x1 Conv for feature map compression\n",
    "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "    # 2x2 Average Pooling for spatial downsampling\n",
    "    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.pool(self.conv(self.relu(self.norm(x))))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1zF9PPbkpdh"
   },
   "source": [
    "Assembling the DenseNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4LRpVwqDklFF"
   },
   "outputs": [],
   "source": [
    "#Creating a simplified DenseNet model\n",
    "class DenseNet_custom(nn.Module):\n",
    "  def __init__(self, growth_rate=12, block_config=(6,12), num_init_features=24, num_classes=10):\n",
    "    super().__init__()\n",
    "\n",
    "    # Initial 3x3 Convolution (CIFAR-10 size doesn't need 7x7 with stride 2)\n",
    "    self.features = nn.Sequential(\n",
    "        nn.Conv2d(3, num_init_features, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(num_init_features),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    # Add Dense Blocks and Transition Layers\n",
    "    num_features = num_init_features\n",
    "    for i, num_layers in enumerate(block_config):\n",
    "      # Adding dense block\n",
    "      block = _DenseBlock(num_layers=num_layers, in_channels=num_features, growth_rate=growth_rate)\n",
    "      self.features.add_module(f'denseblock{i+1}', block)\n",
    "      num_features += num_layers * growth_rate\n",
    "\n",
    "      #Adding transition layer if not the last block\n",
    "      if i != len(block_config) - 1:\n",
    "        # compression factor theta = 0.5 (standard)\n",
    "        out_channels = int(num_features * 0.5)\n",
    "        trans = _Transition(num_features, out_channels)\n",
    "        self.features.add_module(f'transition{i+1}', trans)\n",
    "        num_features = out_channels\n",
    "\n",
    "    #final batch norm and global average pooling\n",
    "    self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "    self.features.add_module('relu5', nn.ReLU(inplace=True))\n",
    "\n",
    "    #final classifier\n",
    "    self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    features = self.features(x)\n",
    "    out = nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
    "    out = torch.flatten(out, 1)\n",
    "    out = self.classifier(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qweb-c5AkeJH"
   },
   "outputs": [],
   "source": [
    "# Instantiate the simplified model\n",
    "# Config (6, 12) means two dense blocks with 6 and 12 layers respectively.\n",
    "# Total layers: 1 (initial) + 2*(6*2) + 2*(12*2) + 2*(Transition) + 1 (Classifier)\n",
    "model = DenseNet_custom().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7Agjqcwugyc",
    "outputId": "be78693a-6c94-44e8-e452-75e386ab52a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet_custom(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (3): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (3): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (6): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (7): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (9): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (10): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (11): _Bottleneck(\n",
      "          (norm1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu5): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=192, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4Do9SN4vqAM"
   },
   "source": [
    "Data loading & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X25LgOmOvMKk"
   },
   "outputs": [],
   "source": [
    "#Load CIFAR-10 data\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yIrFbTSSw0MR"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pC6BJgPMxPgl"
   },
   "outputs": [],
   "source": [
    "#Defining Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=1e-4) # SGD with momentum is common for scratch training\n",
    "# momentum=0.9 : for faster convergence\n",
    "# weight_decay: for overfitting\n",
    "#le-4: L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FAX50_YlyY9s"
   },
   "outputs": [],
   "source": [
    "#training loop\n",
    "def training(model, criterion, optimizer, train_loader, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    model.train() #sets the model to training mode\n",
    "    running_loss = 0.0 #Initializes a float variable to accumulate the loss over all batches in the current epoch.\n",
    "    correct_preds = 0 #Initializes an integer variable to count the number of correct predictions in the current epoch.\n",
    "    total_samples = 0 #Initializes an integer variable to count the total number of processed samples in the current epoch (used for calculating accuracy).\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      optimizer.zero_grad() #Clears the gradients of all optimized parameters. This must be done at the start of every batch iteration, otherwise gradients from previous batches will accumulate.\n",
    "      outputs = model(inputs) #Passes the input data through the neural network model to get the predicted raw scores (logits).\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward() #Computes the gradient of the loss with respect to every model parameter that has requires_grad=True. These gradients are stored in the .grad attribute of the parameters.\n",
    "      optimizer.step() #Updates the model's parameters based on the computed gradients and the optimization algorithm (e.g., SGD, Adam). This is the core learning step.\n",
    "\n",
    "      running_loss += loss.item() * inputs.size(0) #Accumulates the loss. loss.item() extracts the numerical value from the scalar tensor. This is multiplied by the batch size (inputs.size(0)) to get the total loss contribution of the current batch.\n",
    "      _, predicted = torch.max(outputs.data, 1) #Finds the predicted class. torch.max returns the maximum value and its index (the predicted class ID) along dimension 1 (the class dimension). We ignore the maximum value (_) and keep the index (predicted). .data is used to get the tensor without its connection to the computational graph.\n",
    "      total_samples += labels.size(0)\n",
    "      correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss/len(train_loader.dataset)\n",
    "    epoch_acc = correct_preds/total_samples\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veyoAJFC03Bt",
    "outputId": "9cff82a4-faa8-45a3-e81c-f57369fd29d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Loss: 1.5456 | Accuracy: 42.38%\n"
     ]
    }
   ],
   "source": [
    "training(model, criterion, optimizer, train_loader, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
